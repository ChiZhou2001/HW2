import matplotlib.pyplot as plt
import numpy as np
import hdf5storage
import math
from scipy.interpolate import make_interp_spline
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.linear_model import LinearRegression
#Import metrics
from Neural_Decoding.metrics import get_R2
from Neural_Decoding.metrics import get_rho

#Import decoder functions
from Neural_Decoding.decoders import KalmanFilterDecoder,LSTMDecoder

plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签
plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号

'''
实验数据为indy_20160407_02.mat

        cursor_pos(204446,2)
        finger_pos(204446,2)
        target_pos(204446,2)
        t(204446,1)
        spikes(192,3)
        wf(192,3)

神经元选择为spike(33,2)
'''

# 导入数据
file = 'D:\\indy_20160407_02.mat'
data = hdf5storage.loadmat(file, mat_dtype=True)
target_pos = data['target_pos']
cursor_pos = data['cursor_pos']
wf = (np.array([data['wf'][32][0]])).reshape(8092, 48)
wf1 = (np.array([data['wf'][32][1]])).reshape(9652, 48)
wf2 = (np.array([data['wf'][32][2]])).reshape(5310, 48)
t = data['t']
spike = (np.array([data['spikes'][32][1]])).reshape(9652, 1)
spike1 = (np.array([data['spikes'][32][2]])).reshape(5310, 1)

# 找到一个目标位置，在路径图中较为密集
# plt.scatter(target_pos[:, 0], target_pos[:, 1], s=5, c='r')
# plt.plot(cursor_pos[:, 0], cursor_pos[:, 1])
# plt.show()

# 设置固定位置刺激，以（-30，56.4286）为例，如果光标位置距离目标位置的平面距离小于1，则计为有效，然后再手动筛选trial,有效trial数为10
# 取事件开始前200ms，事件发生后1200ms为任务段
target_loc = [-30, 56.4286]
target_time = []
trial_num = 0
for i in range(cursor_pos.shape[0]):
    if math.sqrt(math.pow(target_loc[0] - cursor_pos[i, 0], 2) + math.pow(target_loc[1] - cursor_pos[i, 1], 2)) < 1:
        trial_num += 1
        target_time.append(i)
# print("初筛trial的数目：",trial_num)
# print("初筛trial对应出现的时间戳：",t[target_time])
# 筛选任务期内神经元发出的spike时间戳
raster_matrix = np.zeros((10, 1000))
valid_target_time = np.array([290.824, 347.264, 357.304, 365.276, 432.164, 447.608, 607.404, 655.524, 854.544, 857.008])
for i in range(valid_target_time.shape[0]):
    count = 0
    for j in spike:
        if j > valid_target_time[i] - 0.2 and j < valid_target_time[i] + 1.2:
            raster_matrix[i, count] = j - valid_target_time[i]
            count += 1
raster1_timestamps = [item for item in raster_matrix[0, :] if item != 0]
raster2_timestamps = [item for item in raster_matrix[1, :] if item != 0]
raster3_timestamps = [item for item in raster_matrix[2, :] if item != 0]
raster4_timestamps = [item for item in raster_matrix[3, :] if item != 0]
raster5_timestamps = [item for item in raster_matrix[4, :] if item != 0]
raster6_timestamps = [item for item in raster_matrix[5, :] if item != 0]
raster7_timestamps = [item for item in raster_matrix[6, :] if item != 0]
raster8_timestamps = [item for item in raster_matrix[7, :] if item != 0]
raster9_timestamps = [item for item in raster_matrix[8, :] if item != 0]
raster10_timestamps = [item for item in raster_matrix[9, :] if item != 0]

# 画raster图
# plt.figure(figsize=(10, 6))
# # 绘制每个通道中的神经元时间戳
# for i, timestamps in enumerate(
#         [raster1_timestamps, raster2_timestamps, raster3_timestamps, raster4_timestamps, raster5_timestamps,
#          raster6_timestamps, raster7_timestamps, raster8_timestamps, raster9_timestamps, raster10_timestamps, ]):
#     plt.eventplot(timestamps, lineoffsets=i, linelengths=0.5, linewidths=2, colors=f"C{i}", label=f"Channel {i + 1}")
# # 设置图的标签和标题
# plt.xlabel("time /s")
# plt.ylabel("trial number")
# plt.title(" Raster graph")
# 显示图
# plt.show()

# 创建 PSTH 图
# plt.figure(figsize=(10, 6))
# # 定义 PSTH 的时间窗口参数
# bin_size = 0.02  # 时间窗口大小（秒）
# start_time = -0.2  # PSTH 的起始时间
# end_time = 1.2  # PSTH 的结束时间
# # 计算 PSTH
# raster_matrix = raster_matrix[raster_matrix != 0]
# bin_edges = np.arange(start_time, end_time + bin_size, bin_size)
# psth, _ = np.histogram(raster_matrix, bin_edges)
# # 转换为平均活动率
# bin_counts = np.diff(bin_edges)
# psth = psth / bin_counts
# # 绘制 PSTH 图
# plt.bar(bin_edges[:-1], psth, width=0.01, color='gray')
# plt.xlabel("time /s")
# plt.ylabel("firing rate per second")
# plt.title("PSTH graph")
# plt.show()

# 绘制tunning curve
# 找到每次目标位置变化时，持续的时间和方向
# target共有467次
all_position = []
time_position = []
x = target_pos[0, 0]
y = target_pos[0, 1]
all_position.append(target_pos[0, :])
for i in range(target_pos.shape[0]):
    if target_pos[i, 0] != x and target_pos[i, 1] != y:
        all_position.append(target_pos[i, :])
        time_position.append(t[i])
        x = target_pos[i, 0]
        y = target_pos[i, 1]
all_position = np.array(all_position)
time_position = np.array(time_position)
# print("all_position:", all_position.shape)
# print("time_position:", time_position.shape)
all_angle = []
for i in range(time_position.shape[0]):
    if i == 0:
        angle = math.atan((all_position[i, 1] - 58.5562) / (all_position[i, 0] - 42.1102))
        if all_position[i, 1] - 58.5562 < 0 and all_position[i, 0] - 42.1102 < 0:
            if math.degrees(angle) < 0:
                all_angle.append(math.degrees(angle) + 360)
            else:
                all_angle.append(math.degrees(angle) + 180)
        elif all_position[i, 1] - 58.5562 < 0 < all_position[i, 0] - 42.1102:
            if math.degrees(angle) < 0:
                all_angle.append(math.degrees(angle) + 360)
            else:
                all_angle.append(math.degrees(angle) + 180)
        else:
            if math.degrees(angle) < 0:
                all_angle.append(math.degrees(angle) + 180)
            else:
                all_angle.append(math.degrees(angle))
    else:
        angle = math.atan((all_position[i, 1] - all_position[i - 1, 1]) / (all_position[i, 0] - all_position[i - 1, 0]))
        if all_position[i, 1] - all_position[i - 1, 1] < 0 and all_position[i, 0] - all_position[i - 1, 0] < 0:
            if math.degrees(angle) < 0:
                all_angle.append(math.degrees(angle) + 360)
            else:
                all_angle.append(math.degrees(angle) + 180)
        elif all_position[i, 1] - all_position[i - 1, 1] < 0 < all_position[i, 0] - all_position[i - 1, 0]:
            if math.degrees(angle) < 0:
                all_angle.append(math.degrees(angle) + 360)
            else:
                all_angle.append(math.degrees(angle) + 180)
        else:
            if math.degrees(angle) < 0:
                all_angle.append(math.degrees(angle) + 180)
            else:
                all_angle.append(math.degrees(angle))
all_angle = np.array(all_angle)
# print("all_angle:", all_angle.shape)
# 将运动方向以x轴正向为0度，每45度划分为一个区间
angle_position1 = []
angle_position2 = []
angle_position3 = []
angle_position4 = []
angle_position5 = []
angle_position6 = []
angle_position7 = []
angle_position8 = []
for i in range(all_angle.shape[0]):
    if 0 < all_angle[i] < 45:
        angle_position1.append(i)
    elif 45 < all_angle[i] < 90:
        angle_position2.append(i)
    elif 90 < all_angle[i] < 135:
        angle_position3.append(i)
    elif 135 < all_angle[i] < 180:
        angle_position4.append(i)
    elif 180 < all_angle[i] < 225:
        angle_position5.append(i)
    elif 225 < all_angle[i] < 270:
        angle_position6.append(i)
    elif 270 < all_angle[i] < 315:
        angle_position7.append(i)
    else:
        angle_position8.append(i)
angle_position1 = np.array(angle_position1)
angle_position2 = np.array(angle_position2)
angle_position3 = np.array(angle_position3)
angle_position4 = np.array(angle_position4)
angle_position5 = np.array(angle_position5)
angle_position6 = np.array(angle_position6)
angle_position7 = np.array(angle_position7)
angle_position8 = np.array(angle_position8)
# print(time_position.shape)
# print(time_position)
# print(angle_position1.shape)
# print(angle_position1)
# 根据每个区间对应的时间段神经元的spike发放，绘制tunning curve
angle_position = [angle_position1, angle_position2, angle_position3, angle_position4, angle_position5, angle_position6,
                  angle_position7, angle_position8]
# print("angle_position:", angle_position6)
angle_count = []
for i in angle_position:
    count = 0
    time = 0
    for j in i:
        if j == 0:
            continue
            # for k in spike[0,:]:
            #     if k < time_position[j]:
            #         count += 1
            #         time = time + time_position[j] - 65
        else:
            for k in spike:
                if time_position[j - 1] < k < time_position[j]:
                    count += 1
                    time = time + time_position[j] - time_position[j - 1]
    ct = count / time
    angle_count.extend(ct)
angle_count = np.array(angle_count)
# print(angle_count)
# 画图
x = [1, 2, 3, 4, 5, 6, 7, 8]
x_new = np.linspace(1, 8, 300)
y_smooth = make_interp_spline(x, angle_count)(x_new)
# fig = plt.figure()
# ax = fig.add_subplot(1, 1, 1)
# # ticks在原数据的范围内,设定主刻度的位置
# ax.set_xticks([0, 1, 2, 3, 4, 5, 6, 7, 8])
# # 设置主刻度的标签， 带入主刻度旋转角度和字体大小参数
# ax.set_xticklabels(['0', '45', '90', '135', '180', '225', '270', '315', '360'], rotation=30, fontsize=10)
# ax.scatter(x, angle_count, c='red')
# ax.plot(x_new, y_smooth, c='black')
# plt.xlabel('direction')
# plt.ylabel('impulses /sec')
# plt.title('tunning curve')
# plt.show()

# spike波形原始信号作图
# for i in range(wf.shape[0]):
#     plt.plot(wf[i, :])
# plt.xlabel('time points')
# plt.ylabel('amplitude')
# plt.title('origion spike waves')

# PCA降维和可视化
pca = PCA(n_components=4)
X_new = pca.fit_transform(wf)
# print(X_new.shape)
# plt.scatter(X_new[:, 0], X_new[:, 1], X_new[:, 2], X_new[:, 3])
# plt.title('PCA result')
# plt.show()
# k-means方法聚类
# 创建 K-Means 模型
n_clusters = 2
kmeans = KMeans(n_clusters=n_clusters)
kmeans.fit(X_new)
# 获取簇中心点和分配结果
centers = kmeans.cluster_centers_
labels = kmeans.labels_
# 可视化结果
# plt.scatter(X_new[:, 0], X_new[:, 1], X_new[:, 2], X_new[:, 3])
# plt.scatter(centers[:, 0], centers[:, 1], marker='x', s=200, linewidths=3, color='r')
# plt.title('k-means result')
# plt.show()
# 查看k-means分类分离的spike信号与人工分离的spike信号的区别
# fig, ax = plt.subplots(2, 2)
# for i in range(labels.shape[0]):
#     if labels[i] == 0:
#         ax[0][0].plot(wf[i, :])
#     if labels[i] == 1:
#         ax[1][0].plot(wf[i, :])
# for i in range(wf1.shape[0]):
#     ax[0][1].plot(wf1[i, :])
# for i in range(wf2.shape[0]):
#     ax[1][1].plot(wf2[i, :])
# ax[0][0].set_title('k-meas spike')
# ax[0][1].set_title('spike')
# plt.suptitle('spike constract')
# plt.show()

# 神经元运动调制分析
all_speed = []
for i in range(time_position.shape[0]):
    if i == 0:
        speed = math.sqrt(math.pow(all_position[i, 0] - 42.1102, 2) + math.pow(all_position[i, 1] - 58.5562, 2)) / (
                    time_position[i] - 65)
    else:
        speed = math.sqrt(math.pow(all_position[i, 0] - all_position[i - 1, 0], 2) + math.pow(
            all_position[i, 1] - all_position[i - 1, 1], 2)) / (
                        time_position[i] - time_position[i - 1])
    all_speed.extend(speed)
all_speed = np.array(all_speed)
spike_count = []
for i in range(time_position.shape[0]):
    count = 0
    for j in spike:
        if i == 0:
            if j < time_position[i]:
                count += 1
        else:
            if time_position[i - 1] < j < time_position[i]:
                count += 1
    spike_count.append(count)
spike_count = np.array(spike_count)
# 线性回归
model = LinearRegression()
model.fit(spike_count.reshape((-1, 1)), all_speed)
model = LinearRegression().fit(spike_count.reshape((-1, 1)), all_speed)
r_sq = model.score(spike_count.reshape((-1, 1)), all_speed)
# print('R2:', r_sq)

# 卡尔曼滤波器
# neural_data：横轴为466个时间点，纵轴为2个spike
# pos_binned：横轴为466个位置，纵轴为横纵坐标
neural_data = np.zeros([466,2])
for i in range(time_position.shape[0]):
    count1 = 0
    count2 = 0
    if i == 0:
        for j in spike:
            if j < time_position[0]:
                count1+=1
        for k in spike1:
            if k < time_position[0]:
                count2+=1
    else:
        for j in spike:
            if time_position[i-1] < j < time_position[i]:
                count1+=1
        for k in spike1:
            if time_position[i-1] < k < time_position[i]:
                count2+=1
    neural_data[i, 0] = count1
    neural_data[i, 1] = count2
pos_binned = all_position[0:466, :]
neural_data = np.array(neural_data)
# print(neural_data.shape)
# print(pos_binned.shape)
lag=-1


X_kf=neural_data


temp=np.diff(pos_binned,axis=0)
vels_binned=np.concatenate((temp,temp[-1:,:]),axis=0)
#We now determine acceleration
temp2=np.diff(vels_binned,axis=0)
acc_binned=np.concatenate((temp2,temp2[-1:,:]),axis=0)
y_kf=np.concatenate((pos_binned,vels_binned,acc_binned),axis=1)


rmv_time=np.where(np.isnan(y_kf[:,0]) | np.isnan(y_kf[:,1]))
X_kf=np.delete(X_kf,rmv_time,0)
y_kf=np.delete(y_kf,rmv_time,0)


num_examples=X_kf.shape[0]
#Re-align data to take lag into account
if lag<0:
    y_kf=y_kf[-lag:,:]
    X_kf=X_kf[0:num_examples+lag,:]
if lag>0:
    y_kf=y_kf[0:num_examples-lag,:]
    X_kf=X_kf[lag:num_examples,:]

training_range = [0, 0.5]
valid_range = [0.5, 0.65]
testing_range = [0.65, 0.8]

num_examples_kf = X_kf.shape[0]

# Note that each range has a buffer of 1 bin at the beginning and end
# This makes it so that the different sets don't include overlapping data
training_set = np.arange(np.int_(np.round(training_range[0] * num_examples_kf)) + 1,
                         np.int_(np.round(training_range[1] * num_examples_kf)) - 1)
testing_set = np.arange(np.int_(np.round(testing_range[0] * num_examples_kf)) + 1,
                        np.int_(np.round(testing_range[1] * num_examples_kf)) - 1)
valid_set = np.arange(np.int_(np.round(valid_range[0] * num_examples_kf)) + 1,
                      np.int_(np.round(valid_range[1] * num_examples_kf)) - 1)

# Get training data
X_kf_train = X_kf[training_set, :]
y_kf_train = y_kf[training_set, :]

# Get testing data
X_kf_test = X_kf[testing_set, :]
y_kf_test = y_kf[testing_set, :]

# Get validation data
X_kf_valid = X_kf[valid_set, :]
y_kf_valid = y_kf[valid_set, :]


#Z-score inputs
X_kf_train_mean=np.nanmean(X_kf_train,axis=0)
X_kf_train_std=np.nanstd(X_kf_train,axis=0)
X_kf_train=(X_kf_train-X_kf_train_mean)/X_kf_train_std
X_kf_test=(X_kf_test-X_kf_train_mean)/X_kf_train_std
X_kf_valid=(X_kf_valid-X_kf_train_mean)/X_kf_train_std

#Zero-center outputs
y_kf_train_mean=np.mean(y_kf_train,axis=0)
y_kf_train=y_kf_train-y_kf_train_mean
y_kf_test=y_kf_test-y_kf_train_mean
y_kf_valid=y_kf_valid-y_kf_train_mean


#Declare model
model_kf=KalmanFilterDecoder(C=5) #There is one optional parameter (see ReadMe)

#Fit model
model_kf.fit(X_kf_train,y_kf_train)

#Get predictions
y_valid_predicted_kf=model_kf.predict(X_kf_valid,y_kf_valid)

#Get metrics of fit (see read me for more details on the differences between metrics)
#First I'll get the R^2
R2_kf=get_R2(y_kf_valid,y_valid_predicted_kf)
print('R2:',R2_kf[0:2]) #I'm just printing the R^2's of the 1st and 2nd entries that correspond to the positions
#Next I'll get the rho^2 (the pearson correlation squared)
rho_kf=get_rho(y_kf_valid,y_valid_predicted_kf)
print('rho2:',rho_kf[0:2]**2) #I'm just printing the rho^2's of the 1st and 2nd entries that correspond to the positions
# print(y_kf_valid.shape)
# print(y_kf_train_mean.shape)
# print(y_kf_train_mean)
# print(y_valid_predicted_kf.shape)

#As an example, I plot an example 3000 values of the x position (column index 0), both true and predicted with the Kalman filter
#Note that I add back in the mean value, so that both true and predicted values are in the original coordinates
fig_x_kf=plt.figure()
# plt.plot(y_kf_valid[2000:5000,0]+y_kf_train_mean[0],'b')
plt.plot(y_kf_valid[:,1],'b')
plt.plot(y_valid_predicted_kf[:,1],'r')
plt.show()
#Save figure
fig_x_kf.savefig('x_position_decoding.eps')
fig_x_kf.savefig('x_position_decoding.png')
